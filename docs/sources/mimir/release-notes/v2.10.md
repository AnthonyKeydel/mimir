---
title: "Grafana Mimir version 2.10 release notes"
menuTitle: "V2.10 release notes"
description: "Release notes for Grafana Mimir version 2.10"
weight: 1000
---

# Grafana Mimir version 2.10 release notes

Grafana Labs is excited to announce version 2.10 of Grafana Mimir.

The highlights that follow include the top features, enhancements, and bugfixes in this release. For the complete list of changes, see the [changelog](https://github.com/grafana/mimir/blob/main/CHANGELOG.md).

## Features and enhancements

- The ruler endpoint `/api/v1/rules` now accepts `file`, `ruler_group` and `rule_name` parameters to filter the results.
- The Cardinality API endpoint `/api/v1/cardinality/label_values` now accepts a `count_method` parameter, which can be set to `active` to only **count series that are considered _active_** according to the `-ingester.active-series-metrics-idle-timeout` flag setting rather than counting all inmemory series.
- The internal data structure for labels was changed, reducing the memory consumption. Expect ingesters to use around 15% less memory with this change, depending on the pattern of labels used, number of tenants, etc.
- The memory usage of the Active Series Tracker in the ingester was improved.
- All components now support buffered logging that can be enabled through the `-log.buffered` CLI flag. This should reduce contention and resource usage under heavy usage patterns.
- OTLP ingestion performance was improved and more detailed information was added to the traces in order to improve debugging of OTLP ingestion.
- The performance of series matching in the store-gateway was improved by alwyas including the `__name__` posting group causing a reduction in the number of object storage API calls.
- The performance of _label values with matchers_ calls was improved when number of matched series is small. If you're using Grafana to query Grafana Mimir, please [configure the correct version in your Prometheus datasource](https://grafana.com/docs/grafana/latest/datasources/prometheus/configure-prometheus-data-source/).
- Queriers will now cancel the requests sent to a zone upon receiving first error from that zone, , to reduce wasted effort spent computing results that won't be used.
- Compactor can now clean up bucket index, markers and debug files if no blocks left in the bucket index. This cleanup can be enabled by using `-compactor.no-blocks-file-cleanup-enabled` option.
- The ingesters now expose HTTP endpoints `/ingester/tenants` and `/ingester/tsdb/{tenant}` that provide debug information about tenants and their TSDBs.

## Experimental features

Grafana Mimir 2.10 includes new features that are considered as experimental and disabled by default. Please use them with caution and report any issues you may encounter:

- **Support for ingesting exponential histograms in OpenTelemetry format**. The exponential histograms that are over the native histogram scale limit of 8 can be downscaled to allow their ingestion.
- **Store-gateway index-header loading improvments**, which include the ability to persist the sparse index-header to disk instead of reconstructing it on every restart (`-blocks-storage.bucket-store.index-header-sparse-persistence-enabled`) and an option to limit the number of concurrent index-header loads when lazy-loading (`-blocks-storage.bucket-store.index-header-lazy-loading-concurrency`).
- **Option to allow queriers to reduce pressure on ingesters** by initally querying only the minimum set of ingesters required to reach quorum.
- **Early TSDB Head compaction in the ingesters** to reduce in-memory series when a certain threshold is reached. Useful to deal with sudden cardinality spikes.
- **Support to cache cardinality, label names and label values** query responses in query frontend. The cache will be used when `-query-frontend.cache-results` is enabled, and `-query-frontend.results-cache-ttl-for-cardinality-query` or `-query-frontend.results-cache-ttl-for-labels-query` set to a value greater than 0.
- **Spread-minimizing token generation algorithm** for the ingesters. This new method drastically reduces the difference in series pushed to different ingesters. Please note that [a migration process](https://github.com/grafana/mimir/issues/4736#issuecomment-1602976040) is required to switch from previous random generation algorithm, which will be detailed once the feature is declared stable.
- **Support for chunks streaming from store-gateways to queriers** that should reduce the memory usage in those components. Can be enabled through the `-querier.prefer-streaming-chunks-from-store-gateways` option.
- **Support for circuit-breaking the distributor write requests to the ingesters**. This can be enabled through the `-ingester.client.circuit-breaker.*` configuration options and should serve to let ingesters recover when under high pressure.
- **Support to limit read requests based on CPU/memory utilization**. This should alleviate pressure on the ingesters after receiving heavy queries and reduce the likelihood of disrupting the write path.

### Helm chart improvements

The Grafana Mimir and Grafana Enterprise Metrics Helm chart is now released independently. See the [Grafana Mimir Helm chart documentation](/docs/helm-charts/mimir-distributed/latest/).

## Important changes

In Grafana Mimir 2.10 we have changed the following behaviors:

- Query requests are initiated only to ingesters in the `ACTIVE` state in the ring.
- Per-instance limit errors are not logged anymore, to reduce resource usage when ingesters are under pressure. We encourage to use metrics and alerting to monitor them. The following metrics have been added to count the number of requests rejected for hitting per-instance limits:
  - `cortex_distributor_instance_rejected_requests_total`
  - `cortex_ingester_instance_rejected_requests_total`
- The CLI flag `-validation.create-grace-period` is now enforced in the ingester too, if you've configured `-validation.create-grace-period` then make sure the configuration is applied to ingesters too.
- The CLI flag `-validation.create-grace-period` is now enforced for exemplars too, and the `cortex_discarded_exemplars_total{reason="exemplar_too_far_in_future",user="..."}` series is incremented when exemplars are dropped because their timestamp is greater than "now + grace_period".
- The CLI flag `-validation.create-grace-period` is now enforced in the query-frontend even when the configured value is 0. When the value is 0, the query end time range is truncated to the current real-world time.

The following metrics were removed:

- `cortex_ingester_shipper_dir_syncs_total`
- `cortex_ingester_shipper_dir_sync_failures_total`

The following configuration options are deprecated and will be removed in Grafana Mimir 2.12:

-The CLI flag `-blocks-storage.bucket-store.index-header-lazy-loading-enabled` is deprecated, use the new configuration `-blocks-storage.bucket-store.index-header.lazy-loading-enabled`.
-The CLI flag `-blocks-storage.bucket-store.index-header-lazy-loading-idle-timeout` is deprecated, use the new configuration `-blocks-storage.bucket-store.index-header.lazy-loading-idle-timeout`.
-The CLI flag `-blocks-storage.bucket-store.index-header-lazy-loading-concurrency` is deprecated, use the new configuration `-blocks-storage.bucket-store.index-header.lazy-loading-concurrency`.

The following configuration options that were deprecated in Grafana Mimir 2.8 are removed:

- The CLI flag `blocks-storage.tsdb.max-tsdb-opening-concurrency-on-startup`.

The following experimental configuration options were renamed or removed:

- The CLI flag `-querier.prefer-streaming-chunks` was renamed to `-querier.prefer-streaming-chunks-from-ingesters`.
- The CLI flag `-blocks-storage.bucket-store.chunks-cache.fine-grained-chunks-caching-enabled` was removed.
- The CLI flag `-blocks-storage.bucket-store.fine-grained-chunks-caching-ranges-per-series` was removed.

The following experimental options and features are now stable:

- The CLI flag `-shutdown-delay`.

The following configuration option defaults were changed:

- The default value for the CLI flag `-querier.streaming-chunks-per-ingester-buffer-size` was changed from `512` to `256`.
- The default value for gRPC clients connect timeout was set to `5s` with a default max backoff delay of `5s`.

## Bug fixes

- Ruler: fixed graceful shutdown for rule evaluations.
- Ingester: fixed ingesters getting stuck when previous state is `LEAVING` and the number of tokens has changed upon restarting.
- Querier: fixed `timestamp()` function fail with `execution: attempted to read series at index 0 from stream, but the stream has already been exhausted` if streaming chunks from ingesters to queriers is enabled.
- Memberlist: brought back `memberlist_client_kv_store_count` metric that used to exist in Cortex, but got lost during [grafana/dskit](https://github.com/grafana/dskit/) updates before Mimir 2.0.
- Store-gateway: fixed an issue where stopping a store-gateway could cause all store-gateways to unload all blocks.
- Ingester: prevented setting "last update time" of TSDB into the future when opening TSDB. This could prevent detecting of idle TSDB for a long time, if sample in distant future was ingested.
- General: Allocate ballast in smaller blocks to avoid problem when entire ballast was kept in memory working set.
